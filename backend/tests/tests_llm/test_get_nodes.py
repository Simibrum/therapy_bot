# Generated by CodiumAI

# Dependencies:
# pip install pytest-mock
import pytest
from llm.graph_processing import get_nodes  # Replace 'your_module' with the actual module name


class TestGetNodes:
    def test_generates_nodes_correctly_from_well_formed_input_text(self, mocker, test_nlp):
        api_response = """{
            "nodes": [
                {"label": "Brian", "spans": [[0]]},
                {"label": "fun", "spans": [[4]]}
            ]
        }"""
        mocker.patch("llm.graph_processing.api_request", return_value=api_response)
        doc = test_nlp("Brian has lots of fun!")
        result = get_nodes(doc)
        assert result == [{"label": "Brian", "spans": [[0]]}, {"label": "fun", "spans": [[4]]}]

    def test_handles_empty_input_text(self, mocker, test_nlp):
        mocker.patch("llm.graph_processing.api_request", return_value='{"nodes": []}')
        doc = test_nlp("")
        result = get_nodes(doc)
        assert result == []

    def test_handles_multiple_entities(self, mocker, test_nlp):
        api_response = """{
            "nodes": [
                {"label": "Alice", "spans": [[0]]},
                {"label": "London", "spans": [[3]]},
                {"label": "vacation", "spans": [[5]]}
            ]
        }"""
        mocker.patch("llm.graph_processing.api_request", return_value=api_response)
        doc = test_nlp("Alice went to London for vacation.")
        result = get_nodes(doc)
        assert result == [
            {"label": "Alice", "spans": [[0]]},
            {"label": "London", "spans": [[3]]},
            {"label": "vacation", "spans": [[5]]},
        ]

    def test_handles_multi_token_spans(self, mocker, test_nlp):
        api_response = """{
            "nodes": [
                {"label": "New York", "spans": [[0, 1]]},
                {"label": "popular destination", "spans": [[3, 4]]}
            ]
        }"""
        mocker.patch("llm.graph_processing.api_request", return_value=api_response)
        doc = test_nlp("New York is a popular destination for tourists.")
        result = get_nodes(doc)
        assert result == [{"label": "New York", "spans": [[0, 1]]}, {"label": "popular destination", "spans": [[3, 4]]}]

    def test_handles_api_error(self, mocker, test_nlp):
        mocker.patch("llm.graph_processing.api_request", side_effect=Exception("API Error"))
        doc = test_nlp("This should cause an error.")
        with pytest.raises(Exception, match="API Error"):
            get_nodes(doc)

    def test_correct_prompt_used(self, mocker, test_nlp):
        mock_api_request = mocker.patch("llm.graph_processing.api_request")
        mock_api_request.return_value = '{"nodes": []}'
        doc = test_nlp("Alice went to London.")
        get_nodes(doc)

        called_prompt = mock_api_request.call_args[1]["messages"][1]["content"]
        assert "Please provide the nodes for the knowledge graph based on the following input text." in called_prompt
        assert "Alice went to London." in called_prompt
        assert "Token Indexes:" in called_prompt

    def test_respects_token_indexes(self, mocker, test_nlp):
        api_response = """{
            "nodes": [
                {"label": "Alice", "spans": [[0]]},
                {"label": "London", "spans": [[3]]}
            ]
        }"""
        mocker.patch("llm.graph_processing.api_request", return_value=api_response)
        doc = test_nlp("Alice went to London.")
        result = get_nodes(doc)
        assert result == [{"label": "Alice", "spans": [[0]]}, {"label": "London", "spans": [[3]]}]
        # Check that the spans actually correspond to the correct tokens
        assert doc[result[0]["spans"][0][0]].text == "Alice"
        assert doc[result[1]["spans"][0][0]].text == "London"
